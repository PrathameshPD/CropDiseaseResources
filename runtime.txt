import pandas as pd
import numpy as np
from datetime import timedelta
from typing import Dict, List, Any, Union, Generator
from modules.llm_client.common_utils import AzureChatClient
import json

class GasReconciliationProcessor:
    def __init__(self):
        self.client = AzureChatClient.init_openai_client()
        self.VOLUME_TOLERANCE = 250

    @staticmethod
    def _row_to_dict(row: pd.Series) -> Dict:
        """Convert pandas Series row to dictionary, dropping NaN values."""
        return row.dropna().to_dict()

    def _get_system_prompt(self, km_row: Dict, sap_chunk: List[Dict]) -> str:
        """Generate the system prompt for the LLM."""
        return f"""
You are a Highly Skilled Reconciliation Engine designed to match KM with SAP records. Operate with precision, accuracy and critical analysis.

Input:
- KM Record:
{json.dumps(km_row, indent=2)}

- SAP Records:
{json.dumps(sap_chunk, indent=2)}

Perform advanced matching using the following layered rules:

- A strong match occurs when KM End Date/Time and SAP Movement Date are within ±2 days.
- If this condition is not met, other fields must show strong alignment to justify a match.
- Prefer matches where KM Mode of Tranport ≈ SAP MovementType.
- Allow fuzzy matching (e.g., "tank" ≈ "in-tank").
- Prefer matches where KM R/D = SAP R/D.
- If R/D differs, match is acceptable only if other fields (e.g., date, Mode of Tranport) are strongly aligned.
- Match KM Custody Volume to the closest SAP Inventory Qty within a tolerance of ±250 units.
- Prioritize matches where other fields also align well.

IMPORTANT:
- Each SAP record can be matched only once across all KM records.
- Once matched, a SAP record is excluded from future matches.

Return only the final matched row in this format (pipe-separated, no explanation):

End Date/Time | KM Order# | Customer Order # | BATCH # | Mode of Tranport | Source Container | Destination Container | R/D KM | Product KM | Custody Volume | Product SAP | R/D SAP | MovementType | Movement Date | BOL | Nomination Number | Inventory Qty | ReconciliationStatus | MatchingCriteria

Keep ReconciliationStatus and MatchingCriteria as the second last and last columns.

Set ReconciliationStatus to 'MATCH' if a confident match is found, otherwise 'NO MATCH'.

In MatchingCriteria, briefly explain the key fields that led to the match using concise terms like:

- "Date+Volume"
- "Date+Volume+Mode"
- "Volume+Mode"
- "Volume+Mode+R/D"
- "Date+Volume+Mode+R/D"
- "All Fields"

"""
    @staticmethod
    def _chunk_list(data: List, chunk_size: int) -> Generator[List, None, None]:
        """Split a list into chunks of specified size."""
        for i in range(0, len(data), chunk_size):
            yield data[i:i + chunk_size]

    def _process_data_frames(self, df_km: pd.DataFrame, df_sap: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame]:
        """Process and clean the input dataframes."""
        # Process KM dataframe
        required_columns_km = [
            'End Date/Time', 'KM Order#', 'Customer Order #', 'BATCH #',
            'Mode of Tranport', 'Source Container', 'Destination Container',
            'R/D', 'Product', 'Custody Volume'
        ]
        df_km = df_km[required_columns_km]
        df_km = df_km.rename(columns={"R/D": "R/D KM", "Product": "Product KM"})
        
        # Clean KM data
        df_km['R/D_Cleaned'] = df_km['R/D KM'].astype(str).str.strip().str.lower()
        df_km = df_km[df_km['R/D_Cleaned'] != 'zero']
        df_km.drop(columns=['R/D_Cleaned'], inplace=True)
        df_km.reset_index(drop=True, inplace=True)

        # Process SAP dataframe
        required_columns_sap = [
            'Product', 'R/D', 'MovementType', 'Movement Date', 'BOL',
            'Nomination Number', 'Inventory Qty'
        ]
        df_sap = df_sap[required_columns_sap]
        df_sap = df_sap.rename(columns={"R/D": "R/D SAP", "Product": "Product SAP"})
        
        # Clean SAP data
        df_sap = df_sap[~df_sap['Product SAP'].isin(['#2DSL ULS 15', '#2HO ULS 15'])]
        df_sap.reset_index(drop=True, inplace=True)

        return df_km, df_sap

    def _structure_data(self, df_km: pd.DataFrame, df_sap: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame]:
        """Structure the data by categorizing records based on tranport mode and R/D status."""
        # Structure KM data
        tranport_modes = ['in-tank', 'pipeline', 'barge']
        rd_types = ['receipt', 'delivery', 'variance']
        
        structured_km_dfs = []
        for mode in tranport_modes:
            mode_dfs = []
            for rd in rd_types:
                df = df_km[
                    (df_km['Mode of Tranport'].str.lower() == mode) & 
                    (df_km['R/D KM'].str.lower() == rd)
                ]
                mode_dfs.append(df)
            structured_km_dfs.append(pd.concat(mode_dfs, ignore_index=True))
        
        # Add variance records
        variance_df = df_km[df_km['R/D KM'].str.lower() == 'variance']
        structured_km_dfs.append(variance_df)
        
        # Structure SAP data
        structured_sap_dfs = []
        for mode in ['in-tank/inter-tank', 'pipeline', 'barge', 'vessel', 'not assigned']:
            mode_dfs = []
            for rd in ['receipt', 'delivery', '#']:
                df = df_sap[
                    (df_sap['MovementType'].str.lower() == mode) & 
                    (df_sap['R/D SAP'].str.lower() == rd)
                ]
                mode_dfs.append(df)
            structured_sap_dfs.append(pd.concat(mode_dfs, ignore_index=True))

        return (
            pd.concat(structured_km_dfs, ignore_index=True),
            pd.concat(structured_sap_dfs, ignore_index=True)
        )

    def reconcile_data(self, km_df: pd.DataFrame, sap_df: pd.DataFrame, chunk_size: int = 75) -> pd.DataFrame:
        """Reconcile KM and SAP data using LLM."""
        matched_records = []
        matched_sap_indices = set()

        for idx, km_row in enumerate(km_df.itertuples()):
            km_dict = self._row_to_dict(pd.Series(km_row._asdict()))

            try:
                km_date = pd.to_datetime(km_dict.get("End Date/Time"))
                sap_filtered = sap_df[
                    (pd.to_datetime(sap_df["Movement Date"]) >= km_date - timedelta(days=2)) &
                    (pd.to_datetime(sap_df["Movement Date"]) <= km_date + timedelta(days=2))
                ]
            except Exception as e:
                print(f"[Warning] Date filtering failed at KM index {idx}: {e}")
                sap_filtered = sap_df

            sap_filtered = sap_filtered[~sap_filtered.index.isin(matched_sap_indices)]
            sap_records = [(i, self._row_to_dict(row)) for i, row in sap_filtered.iterrows()]
            match_found = False

            for chunk in self._chunk_list(sap_records, chunk_size):
                sap_chunk_dicts = [record for _, record in chunk]
                prompt = self._get_system_prompt(km_dict, sap_chunk_dicts)

                try:
                    response = self.client.chat.completions.create(
                        messages=[{"role": "system", "content": prompt}],
                        temperature=0,
                        max_tokens=1000,
                    )
                    output = response.choices[0].message.content.strip()
                    fields = output.split("|")

                    if len(fields) == 19:
                        record = self._process_llm_output(fields)
                        
                        if record["ReconciliationStatus"] == "MATCH":
                            for i, sap_row in chunk:
                                if (sap_row.get("BOL", "").strip() == record["BOL"] and 
                                    sap_row.get("Nomination Number", "").strip() == record["Nomination Number"]):
                                    matched_sap_indices.add(i)
                                    break

                            matched_records.append(record)
                            match_found = True
                            break

                except Exception as e:
                    print(f"[Error] Matching failed at KM index {idx}: {e}")
                    continue

            if not match_found:
                km_dict["ReconciliationStatus"] = "NO MATCH"
                km_dict["MatchingCriteria"] = "N/A"
                matched_records.append(km_dict)

        # Add unmatched SAP records
        for i, sap_row in sap_df.iterrows():
            if i not in matched_sap_indices:
                sap_dict = self._row_to_dict(sap_row)
                sap_dict["ReconciliationStatus"] = "NO MATCH"
                sap_dict["MatchingCriteria"] = "N/A"
                matched_records.append(sap_dict)

        return pd.DataFrame(matched_records)

    @staticmethod
    def _process_llm_output(fields: List[str]) -> Dict[str, str]:
        """Process LLM output fields into a structured record."""
        field_names = [
            "End Date/Time", "KM Order#", "Customer Order #", "BATCH #",
            "Mode of Tranport", "Source Container", "Destination Container",
            "R/D KM", "Product KM", "Custody Volume", "Product SAP",
            "R/D SAP", "MovementType", "Movement Date", "BOL",
            "Nomination Number", "Inventory Qty", "ReconciliationStatus",
            "MatchingCriteria"
        ]
        return {name: field.strip() for name, field in zip(field_names, fields)}

    def process_reconciliation_results(self, df_matched: pd.DataFrame) -> pd.DataFrame:
        """Process and categorize reconciliation results."""
        df = df_matched.copy()
        
        # Convert to numeric
        df["Custody Volume"] = pd.to_numeric(df["Custody Volume"], errors='coerce')
        df["Inventory Qty"] = pd.to_numeric(df["Inventory Qty"], errors='coerce')
        
        # Calculate variance
        df["Variance"] = df["Inventory Qty"] - df["Custody Volume"]
        df["Variance Status"] = np.where(
            df["Variance"].abs() <= self.VOLUME_TOLERANCE,
            "Match",
            "Open Item"
        )
        
        # Update reconciliation status
        df.loc[
            (df["Variance Status"] == "Open Item") & 
            (df["ReconciliationStatus"] == "MATCH"),
            "ReconciliationStatus"
        ] = "PARTIAL MATCH"
        
        return df

    def generate_excel_report(self, df_matched: pd.DataFrame, output_path: str) -> str:
        """Generate detailed Excel report with multiple sheets."""
        df = self.process_reconciliation_results(df_matched)
        
        # Normalize text columns
        for col in ["Mode of Tranport", "R/D KM", "ReconciliationStatus"]:
            df[col] = df[col].apply(lambda s: str(s).strip().upper())
        
        # Define conditions for different sheets
        conditions = self._get_sheet_conditions(df)
        
        # Define column groupings
        column_groups = self._get_column_groupings()
        
        # Write to Excel
        with pd.ExcelWriter(output_path, engine="openpyxl") as writer:
            for sheet_name, condition in conditions.items():
                df_filtered = df[condition].copy()
                df_filtered = self._prepare_sheet_data(
                    df_filtered, 
                    sheet_name, 
                    column_groups[sheet_name]
                )
                df_filtered.to_excel(writer, sheet_name=sheet_name, index=True)
        
        return output_path

    @staticmethod
    def _get_sheet_conditions(df: pd.DataFrame) -> Dict[str, Any]:
        """Define conditions for different sheets in the report."""
        return {
            "InTank-Receipts": (df["Mode of Tranport"] == "IN-TANK") &
                              (df["R/D KM"] == "RECEIPT") &
                              (df["ReconciliationStatus"] == "MATCH") &
                              (df["Variance Status"] == "Match"),
            "InTank-Delivery": (df["Mode of Tranport"] == "IN-TANK") &
                              (df["R/D KM"] == "DELIVERY") &
                              (df["ReconciliationStatus"] == "MATCH") &
                              (df["Variance Status"] == "Match"),
            "Pipeline-Receipts": (df["Mode of Tranport"] == "PIPELINE") &
                                (df["R/D KM"] == "RECEIPT") &
                                (df["ReconciliationStatus"] == "MATCH") &
                                (df["Variance Status"] == "Match"),
            "Pipeline-Delivery": (df["Mode of Tranport"] == "PIPELINE") &
                                (df["R/D KM"] == "DELIVERY") &
                                (df["ReconciliationStatus"] == "MATCH") &
                                (df["Variance Status"] == "Match"),
            "Barge-Vessel Receipts": df["Mode of Tranport"].isin(["BARGE", "VESSEL"]) &
                                    (df["R/D KM"] == "RECEIPT") &
                                    (df["ReconciliationStatus"] == "MATCH") &
                                    (df["Variance Status"] == "Match"),
            "Barge-Vessel Delivery": df["Mode of Tranport"].isin(["BARGE", "VESSEL"]) &
                                    (df["R/D KM"] == "DELIVERY") &
                                    (df["ReconciliationStatus"] == "MATCH") &
                                    (df["Variance Status"] == "Match"),
            "Open Items": (df["Variance Status"] == "Open Item") |
                         (df["ReconciliationStatus"] != "MATCH")
        }

    @staticmethod
    def _get_column_groupings() -> Dict[str, Dict[str, List[str]]]:
        """Define column groupings for the report."""
        common_km_cols = [
            'End Date/Time', 'KM Order#', 'Customer Order #', 'BATCH #',
            'Mode of Tranport', 'Source Container', 'Destination Container',
            'R/D KM', 'Product KM', 'Custody Volume'
        ]
        common_sap_cols = [
            'Product SAP', 'R/D SAP', 'MovementType', 'Movement Date',
            'BOL', 'Nomination Number', 'Inventory Qty'
        ]
        result_cols = [
            'ReconciliationStatus', 'MatchingCriteria', 'Variance',
            'Variance Status'
        ]
        
        return {
            sheet: {
                "KinderMorgan": common_km_cols,
                "SAP": common_sap_cols,
                "Result": result_cols
            } for sheet in [
                "InTank-Receipts", "InTank-Delivery",
                "Pipeline-Receipts", "Pipeline-Delivery",
                "Barge-Vessel Receipts", "Barge-Vessel Delivery",
                "Open Items"
            ]
        }

    @staticmethod
    def _prepare_sheet_data(
        df: pd.DataFrame,
        sheet_name: str,
        column_groups: Dict[str, List[str]]
    ) -> pd.DataFrame:
        """Prepare data for a specific sheet with proper column ordering and MultiIndex."""
        # Get all available columns in the correct order
        all_cols = []
        for group in ["KinderMorgan", "SAP", "Result"]:
            all_cols.extend(col for col in column_groups[group] if col in df.columns)
        
        # Reorder columns
        df = df[all_cols]
        
        # Create MultiIndex columns
        multi_cols = []
        for col in df.columns:
            group = next(
                (g for g, cols in column_groups.items() if col in cols),
                "Other"
            )
            multi_cols.append((f"{sheet_name} GAS Reconciliation", group, col))
        
        df.columns = pd.MultiIndex.from_tuples(multi_cols)
        return df


def get_GAS_report(km_data: Union[str, pd.DataFrame], sap_data: Union[str, pd.DataFrame], output_path: str) -> str:
    """
    Process GAS reconciliation report from KM and SAP data.
    
    Args:
        km_data: Either a path to Excel file or a pandas DataFrame with KM data
        sap_data: Either a path to Excel file or a pandas DataFrame with SAP data
        output_path: Path where the output Excel report should be saved
        
    Returns:
        str: Path to the generated report
    """
    processor = GasReconciliationProcessor()
    
    # Load data if paths are provided
    if isinstance(km_data, str):
        km_df = pd.read_excel(km_data, sheet_name='KM Raw GAS')
    else:
        km_df = km_data
        
    if isinstance(sap_data, str):
        sap_df = pd.read_excel(sap_data, sheet_name='SAP (All Products)')
    else:
        sap_df = sap_data
    
    # Process and clean the dataframes
    km_df, sap_df = processor._process_data_frames(km_df, sap_df)
    
    # Structure the data
    structured_km_df, structured_sap_df = processor._structure_data(km_df, sap_df)
    
    # Perform reconciliation
    matched_df = processor.reconcile_data(structured_km_df, structured_sap_df)
    
    # Generate and save report
    return processor.generate_excel_report(matched_df, output_path)
